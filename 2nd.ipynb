{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac0566f-9af4-40d3-9766-617b94bb79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 데이터 세트를 이용하여 다이아몬드 가격예측(회귀) \n",
    "\n",
    "# url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\" diamonds = pd.read_csv(url) \n",
    "\n",
    "# 1. ML (RF, DT, LR) 수행\n",
    "\n",
    "# 2. Dense layer만 이용 FNCC 구현\n",
    "\n",
    "# 3. 순환 데이터 변환후 CNN 구현\n",
    "\n",
    "\n",
    "\n",
    "# 각 단계별로 수행완료후\n",
    "\n",
    "# 검사받은 이후에 다음 단계 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4dbbbde-df8e-42f0-86e5-f43f67e8262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde01c80-06e5-4a21-bbdc-1a906abfb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드 및 전처리\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f22f2ed-71e7-417d-a526-5e432b3afddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d6bef3-fa25-4697-b7c4-790592312238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "df = pd.get_dummies(df, columns=['cut','color','clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e817122-588d-41b4-9a38-1b2d2c3329c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table  price     x     y     z  cut_Fair  cut_Good  \\\n",
       "0       0.23   61.5   55.0    326  3.95  3.98  2.43     False     False   \n",
       "1       0.21   59.8   61.0    326  3.89  3.84  2.31     False     False   \n",
       "2       0.23   56.9   65.0    327  4.05  4.07  2.31     False      True   \n",
       "3       0.29   62.4   58.0    334  4.20  4.23  2.63     False     False   \n",
       "4       0.31   63.3   58.0    335  4.34  4.35  2.75     False      True   \n",
       "...      ...    ...    ...    ...   ...   ...   ...       ...       ...   \n",
       "53935   0.72   60.8   57.0   2757  5.75  5.76  3.50     False     False   \n",
       "53936   0.72   63.1   55.0   2757  5.69  5.75  3.61     False      True   \n",
       "53937   0.70   62.8   60.0   2757  5.66  5.68  3.56     False     False   \n",
       "53938   0.86   61.0   58.0   2757  6.15  6.12  3.74     False     False   \n",
       "53939   0.75   62.2   55.0   2757  5.83  5.87  3.64     False     False   \n",
       "\n",
       "       cut_Ideal  ...  color_I  color_J  clarity_I1  clarity_IF  clarity_SI1  \\\n",
       "0           True  ...    False    False       False       False        False   \n",
       "1          False  ...    False    False       False       False         True   \n",
       "2          False  ...    False    False       False       False        False   \n",
       "3          False  ...     True    False       False       False        False   \n",
       "4          False  ...    False     True       False       False        False   \n",
       "...          ...  ...      ...      ...         ...         ...          ...   \n",
       "53935       True  ...    False    False       False       False         True   \n",
       "53936      False  ...    False    False       False       False         True   \n",
       "53937      False  ...    False    False       False       False         True   \n",
       "53938      False  ...    False    False       False       False        False   \n",
       "53939       True  ...    False    False       False       False        False   \n",
       "\n",
       "       clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  \n",
       "0             True        False        False         False         False  \n",
       "1            False        False        False         False         False  \n",
       "2            False         True        False         False         False  \n",
       "3            False        False         True         False         False  \n",
       "4             True        False        False         False         False  \n",
       "...            ...          ...          ...           ...           ...  \n",
       "53935        False        False        False         False         False  \n",
       "53936        False        False        False         False         False  \n",
       "53937        False        False        False         False         False  \n",
       "53938         True        False        False         False         False  \n",
       "53939         True        False        False         False         False  \n",
       "\n",
       "[53940 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76593aa-1e8a-4ef1-811b-4f13435068c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "X = df.drop(['price'], axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ed179e-aa2d-4681-8b85-f7e5ba0d0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 제거\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55ab5e0-341d-49f0-9c7a-649aa3adb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 특성들에 대해 이상치 제거\n",
    "columns_to_clean = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "for column in columns_to_clean:\n",
    "    df = remove_outliers(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3360ec-9920-445d-ab10-b2d5d7229fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7775e565-4bdd-4838-beef-432b88451d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 입력을 위한 reshape\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7f5e48-35df-4e7d-b9bd-a8420bf0729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y_scaled, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "912768ef-ff2b-49ab-9358-12d44cf07277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CNN 모델 구성\n",
    "model = Sequential([    \n",
    "    # Dense 레이어\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e553d34a-d0bc-43ee-9aca-d01ba13b35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2b7ebd-296e-4a48-9411-2e8ac8477ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.3875 - mae: 0.4412 - val_loss: 0.0432 - val_mae: 0.1409\n",
      "Epoch 2/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.1124 - mae: 0.2323 - val_loss: 0.0374 - val_mae: 0.1305\n",
      "Epoch 3/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0879 - mae: 0.1969 - val_loss: 0.0303 - val_mae: 0.1071\n",
      "Epoch 4/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0803 - mae: 0.1887 - val_loss: 0.0293 - val_mae: 0.1066\n",
      "Epoch 5/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0667 - mae: 0.1736 - val_loss: 0.0295 - val_mae: 0.1047\n",
      "Epoch 6/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0651 - mae: 0.1695 - val_loss: 0.0284 - val_mae: 0.1103\n",
      "Epoch 7/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0651 - mae: 0.1678 - val_loss: 0.0320 - val_mae: 0.1130\n",
      "Epoch 8/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0585 - mae: 0.1612 - val_loss: 0.0277 - val_mae: 0.1046\n",
      "Epoch 9/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0536 - mae: 0.1556 - val_loss: 0.0388 - val_mae: 0.1170\n",
      "Epoch 10/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0532 - mae: 0.1513 - val_loss: 0.0256 - val_mae: 0.1027\n",
      "Epoch 11/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0530 - mae: 0.1516 - val_loss: 0.0251 - val_mae: 0.0889\n",
      "Epoch 12/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0485 - mae: 0.1441 - val_loss: 0.0284 - val_mae: 0.0916\n",
      "Epoch 13/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0480 - mae: 0.1433 - val_loss: 0.0245 - val_mae: 0.0893\n",
      "Epoch 14/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0449 - mae: 0.1395 - val_loss: 0.0342 - val_mae: 0.0975\n",
      "Epoch 15/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0463 - mae: 0.1394 - val_loss: 0.0239 - val_mae: 0.0884\n",
      "Epoch 16/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0436 - mae: 0.1345 - val_loss: 0.0226 - val_mae: 0.0872\n",
      "Epoch 17/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0418 - mae: 0.1316 - val_loss: 0.0240 - val_mae: 0.0914\n",
      "Epoch 18/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0408 - mae: 0.1305 - val_loss: 0.0242 - val_mae: 0.0906\n",
      "Epoch 19/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.1266 - val_loss: 0.0245 - val_mae: 0.0972\n",
      "Epoch 20/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1225 - val_loss: 0.0229 - val_mae: 0.0848\n",
      "Epoch 21/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0377 - mae: 0.1221 - val_loss: 0.0249 - val_mae: 0.1017\n",
      "Epoch 22/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0366 - mae: 0.1207 - val_loss: 0.0272 - val_mae: 0.1076\n",
      "Epoch 23/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.1214 - val_loss: 0.0396 - val_mae: 0.1422\n",
      "Epoch 24/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1198 - val_loss: 0.0249 - val_mae: 0.0900\n",
      "Epoch 25/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0354 - mae: 0.1185 - val_loss: 0.0244 - val_mae: 0.1000\n",
      "Epoch 26/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0372 - mae: 0.1205 - val_loss: 0.0274 - val_mae: 0.1026\n",
      "Epoch 27/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1149 - val_loss: 0.0267 - val_mae: 0.1154\n",
      "Epoch 28/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1166 - val_loss: 0.0315 - val_mae: 0.1245\n",
      "Epoch 29/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1160 - val_loss: 0.0333 - val_mae: 0.1109\n",
      "Epoch 30/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1161 - val_loss: 0.0280 - val_mae: 0.1137\n",
      "Epoch 31/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0339 - mae: 0.1153 - val_loss: 0.0291 - val_mae: 0.1180\n",
      "Epoch 32/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0345 - mae: 0.1174 - val_loss: 0.0278 - val_mae: 0.1182\n",
      "Epoch 33/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.1154 - val_loss: 0.0293 - val_mae: 0.1126\n",
      "Epoch 34/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0328 - mae: 0.1147 - val_loss: 0.0237 - val_mae: 0.0975\n",
      "Epoch 35/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.1139 - val_loss: 0.0261 - val_mae: 0.0987\n",
      "Epoch 36/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0329 - mae: 0.1131 - val_loss: 0.0308 - val_mae: 0.1284\n",
      "Epoch 37/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0311 - mae: 0.1116 - val_loss: 0.0351 - val_mae: 0.1440\n",
      "Epoch 38/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0313 - mae: 0.1126 - val_loss: 0.0502 - val_mae: 0.1523\n",
      "Epoch 39/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0315 - mae: 0.1119 - val_loss: 0.0275 - val_mae: 0.1040\n",
      "Epoch 40/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0317 - mae: 0.1122 - val_loss: 0.0310 - val_mae: 0.1270\n",
      "Epoch 41/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0309 - mae: 0.1115 - val_loss: 0.0270 - val_mae: 0.1158\n",
      "Epoch 42/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0303 - mae: 0.1095 - val_loss: 0.0391 - val_mae: 0.1540\n",
      "Epoch 43/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.1105 - val_loss: 0.0314 - val_mae: 0.1323\n",
      "Epoch 44/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0317 - mae: 0.1112 - val_loss: 0.0267 - val_mae: 0.1104\n",
      "Epoch 45/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0306 - mae: 0.1099 - val_loss: 0.0403 - val_mae: 0.1547\n",
      "Epoch 46/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.1122 - val_loss: 0.0322 - val_mae: 0.1333\n",
      "Epoch 47/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0308 - mae: 0.1106 - val_loss: 0.0260 - val_mae: 0.1120\n",
      "Epoch 48/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.1113 - val_loss: 0.0238 - val_mae: 0.0966\n",
      "Epoch 49/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0295 - mae: 0.1087 - val_loss: 0.0251 - val_mae: 0.1038\n",
      "Epoch 50/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.1072 - val_loss: 0.0353 - val_mae: 0.1259\n",
      "Epoch 51/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.1099 - val_loss: 0.0286 - val_mae: 0.1141\n",
      "Epoch 52/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1077 - val_loss: 0.0257 - val_mae: 0.1073\n",
      "Epoch 53/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0290 - mae: 0.1083 - val_loss: 0.0284 - val_mae: 0.1218\n",
      "Epoch 54/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0291 - mae: 0.1081 - val_loss: 0.0313 - val_mae: 0.1326\n",
      "Epoch 55/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1093 - val_loss: 0.0235 - val_mae: 0.0994\n",
      "Epoch 56/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1086 - val_loss: 0.0330 - val_mae: 0.1387\n",
      "Epoch 57/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.1084 - val_loss: 0.0309 - val_mae: 0.1264\n",
      "Epoch 58/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1074 - val_loss: 0.0262 - val_mae: 0.1132\n",
      "Epoch 59/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0302 - mae: 0.1084 - val_loss: 0.0252 - val_mae: 0.1047\n",
      "Epoch 60/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0292 - mae: 0.1076 - val_loss: 0.0301 - val_mae: 0.1282\n",
      "Epoch 61/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.1087 - val_loss: 0.0282 - val_mae: 0.1176\n",
      "Epoch 62/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.1070 - val_loss: 0.0327 - val_mae: 0.1334\n",
      "Epoch 63/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0292 - mae: 0.1080 - val_loss: 0.0276 - val_mae: 0.1146\n",
      "Epoch 64/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0290 - mae: 0.1075 - val_loss: 0.0300 - val_mae: 0.1221\n",
      "Epoch 65/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1074 - val_loss: 0.0287 - val_mae: 0.1190\n",
      "Epoch 66/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.1061 - val_loss: 0.0223 - val_mae: 0.0867\n",
      "Epoch 67/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.1066 - val_loss: 0.0278 - val_mae: 0.1141\n",
      "Epoch 68/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0275 - mae: 0.1040 - val_loss: 0.0276 - val_mae: 0.1162\n",
      "Epoch 69/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.1056 - val_loss: 0.0254 - val_mae: 0.1119\n",
      "Epoch 70/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0279 - mae: 0.1057 - val_loss: 0.0279 - val_mae: 0.1156\n",
      "Epoch 71/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0289 - mae: 0.1071 - val_loss: 0.0244 - val_mae: 0.1050\n",
      "Epoch 72/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0272 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.0992\n",
      "Epoch 73/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0277 - mae: 0.1057 - val_loss: 0.0274 - val_mae: 0.1182\n",
      "Epoch 74/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0277 - mae: 0.1056 - val_loss: 0.0268 - val_mae: 0.1137\n",
      "Epoch 75/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0273 - mae: 0.1036 - val_loss: 0.0226 - val_mae: 0.0930\n",
      "Epoch 76/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0292 - mae: 0.1075 - val_loss: 0.0308 - val_mae: 0.1244\n",
      "Epoch 77/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0271 - mae: 0.1040 - val_loss: 0.0260 - val_mae: 0.1102\n",
      "Epoch 78/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0282 - mae: 0.1052 - val_loss: 0.0250 - val_mae: 0.0974\n",
      "Epoch 79/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0278 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1057\n",
      "Epoch 80/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0271 - mae: 0.1043 - val_loss: 0.0301 - val_mae: 0.1208\n",
      "Epoch 81/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0281 - mae: 0.1050 - val_loss: 0.0228 - val_mae: 0.0966\n",
      "Epoch 82/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0276 - mae: 0.1056 - val_loss: 0.0265 - val_mae: 0.1135\n",
      "Epoch 83/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0274 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1024\n",
      "Epoch 84/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0263 - mae: 0.1021 - val_loss: 0.0234 - val_mae: 0.0978\n",
      "Epoch 85/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0263 - mae: 0.1026 - val_loss: 0.0290 - val_mae: 0.1223\n",
      "Epoch 86/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0262 - mae: 0.1024 - val_loss: 0.0272 - val_mae: 0.1182\n",
      "Epoch 87/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0284 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1019\n",
      "Epoch 88/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0273 - mae: 0.1030 - val_loss: 0.0327 - val_mae: 0.1363\n",
      "Epoch 89/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0272 - mae: 0.1045 - val_loss: 0.0231 - val_mae: 0.0989\n",
      "Epoch 90/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0269 - mae: 0.1042 - val_loss: 0.0276 - val_mae: 0.1147\n",
      "Epoch 91/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0267 - mae: 0.1027 - val_loss: 0.0275 - val_mae: 0.1147\n",
      "Epoch 92/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0281 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1028\n",
      "Epoch 93/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0271 - mae: 0.1027 - val_loss: 0.0274 - val_mae: 0.1147\n",
      "Epoch 94/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0268 - mae: 0.1028 - val_loss: 0.0243 - val_mae: 0.1032\n",
      "Epoch 95/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.1021 - val_loss: 0.0322 - val_mae: 0.1369\n",
      "Epoch 96/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0266 - mae: 0.1036 - val_loss: 0.0269 - val_mae: 0.1090\n",
      "Epoch 97/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0265 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.0855\n",
      "Epoch 98/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0266 - mae: 0.1018 - val_loss: 0.0284 - val_mae: 0.1167\n",
      "Epoch 99/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0275 - mae: 0.1035 - val_loss: 0.0249 - val_mae: 0.1057\n",
      "Epoch 100/100\n",
      "\u001b[1m1079/1079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0255 - mae: 0.1010 - val_loss: 0.0242 - val_mae: 0.1012\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04607237-7a45-45a5-8f74-cfcc9f638dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 평가\n",
    "y_pred_scaled = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "845d67d8-c6a0-4a22-905c-d84ba33624e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값을 원래 스케일로 변환\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_orig = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49df7b82-3fbb-4705-b4b7-a44ff51c26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표 계산\n",
    "mse = mean_squared_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_orig, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccdf45bf-cf09-4c4e-978b-42e12dbd942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 379732.4826\n",
      "RMSE: 616.2244\n",
      "R2 Score: 0.9761\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R2 Score: {r2:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
